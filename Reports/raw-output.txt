
(is_env) shreyas@Shreyas-Macbook-Air Airflow-rate-prediction % python -u "/Users/shreyas/Desktop/UoU/Independent-Study/Airflow-rate-prediction/src/main.py"
--- Starting Airflow Prediction Experiment (with CV) ---
--- NOTE: CNN Features, PCA, RFECV, and Ensemble are DISABLED for this run ---
Starting data loading from: /Users/shreyas/Desktop/UoU/Independent-Study/Airflow-rate-prediction/dataset_new
Processing folder: FanPower_1.6V (Airflow Rate: 1.6)
Processing folder: FanPower_1.8V (Airflow Rate: 1.8)
Processing folder: FanPower_2.1V (Airflow Rate: 2.1)
Processing folder: FanPower_2.4V (Airflow Rate: 2.4)
Finished data loading. Found 22 samples.

--- Extracting Handcrafted Features Only ---
Extracting features for sample 1/22: temp_2025-3-7-19-14-21_21.4_35_13.6_.mat
Extracting features for sample 2/22: temp_2025-3-7-19-19-42_21.4_32.5_11.1_.mat
Extracting features for sample 3/22: temp_2025-3-7-19-26-18_21.4_30_8.6_.mat
Extracting features for sample 4/22: temp_2025-3-7-19-36-44_21.4_27.5_6.1_.mat
Extracting features for sample 5/22: temp_2025-3-7-19-45-8_21.4_26_4.6_.mat
Extracting features for sample 6/22: temp_2025-3-7-17-14-11_21.4_35_13.6_.mat
Extracting features for sample 7/22: temp_2025-3-7-17-19-46_21.4_32.5_11.1_.mat
Extracting features for sample 8/22: temp_2025-3-7-17-26-11_21.4_30_8.6_.mat
Extracting features for sample 9/22: temp_2025-3-7-17-37-1_21.4_27.5_6.1_.mat
Extracting features for sample 10/22: temp_2025-3-7-17-45-42_21.4_26_4.6_.mat
Extracting features for sample 11/22: temp_2025-3-7-18-12-0_21.4_32.5_11.1_.mat
Extracting features for sample 12/22: temp_2025-3-7-18-35-19_21.4_30_8.6_.mat
Extracting features for sample 13/22: temp_2025-3-7-18-45-41_21.4_27.5_6.1_.mat
Extracting features for sample 14/22: temp_2025-3-7-18-54-33_21.4_26_4.6_.mat
Extracting features for sample 15/22: temp_2025-3-7-18-56-59_21.4_26_4.6_.mat
Extracting features for sample 16/22: temp_2025-3-7-18-6-40_21.4_35_13.6_.mat
Extracting features for sample 17/22: temp_2025-2-27-18-31-1_21.7_35_13.3_.mat
Extracting features for sample 18/22: temp_2025-2-27-18-36-28_21.7_32.5_10.8_.mat
Extracting features for sample 19/22: temp_2025-2-27-18-38-31_21.7_32.5_10.8_.mat
Extracting features for sample 20/22: temp_2025-2-27-18-44-39_21.7_30_8.3_.mat
Extracting features for sample 21/22: temp_2025-2-27-18-55-1_21.7_27.5_5.8_.mat
Extracting features for sample 22/22: temp_2025-2-27-19-5-7_21.7_26_4.3_.mat
Feature extraction took: 48.39 seconds.

--- Feature DataFrame Head (Handcrafted + DeltaT) ---
   mean_temp  std_temp   max_temp   min_temp  median_temp  ...  max_spatial_grad  skew_spatial_grad  kurt_spatial_grad  delta_T  airflow_rate
0  24.228506  0.686473  27.445784  22.179819    23.086412  ...          0.826620          -0.282059           0.926882     13.6           1.6
1  24.128073  0.610163  26.815746  22.179819    23.100088  ...          0.679885          -0.072151           0.800556     11.1           1.6
2  23.962002  0.508202  26.221485  22.110783    23.086412  ...          0.540713           0.255706           0.993851      8.6           1.6
3  23.706793  0.385204  25.703587  22.041706    23.031712  ...          0.496473           0.737591           1.647682      6.1           1.6
4  23.580242  0.311180  25.370190  22.124599    23.045387  ...          0.527449           0.807483           1.758842      4.6           1.6

[5 rows x 25 columns]

DataFrame shape: (22, 25)

Label Encoding Mapping: {np.int64(0): '1.6', np.int64(1): '1.8', np.int64(2): '2.1', np.int64(3): '2.4'}

--- Running Hyperparameter Tuning for All Models ---

--- Running Grid Search for LogisticRegression ---

--- Running Grid Search for LogisticRegression ---
Warning: Parameter grid is empty. GridSearch will only fit the default pipeline.
Using LeaveOneOut for GridSearch CV.
GridSearch completed for LogisticRegression. Best Score (f1_weighted): 0.4545
No hyperparameters were tuned (param_grid was empty).

--- Running Grid Search for RandomForest ---

--- Running Grid Search for RandomForest ---
Using LeaveOneOut for GridSearch CV.
GridSearch completed for RandomForest. Best Score (f1_weighted): 0.3636
Best Parameters for RandomForest: {'model__max_depth': 3, 'model__min_samples_split': 2, 'model__n_estimators': 50}

--- Running Grid Search for GradientBoosting ---

--- Running Grid Search for GradientBoosting ---
Using LeaveOneOut for GridSearch CV.
GridSearch completed for GradientBoosting. Best Score (f1_weighted): 0.4091
Best Parameters for GradientBoosting: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 50}

--- Running Grid Search for SVC ---

--- Running Grid Search for SVC ---
Using LeaveOneOut for GridSearch CV.
GridSearch completed for SVC. Best Score (f1_weighted): 0.6818
Best Parameters for SVC: {'model__C': 5.0, 'model__kernel': 'linear'}

--- Tuning Results Summary ---
LogisticRegression: Best Score = 0.4545, Best Params = {}
RandomForest: Best Score = 0.3636, Best Params = {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 50}
GradientBoosting: Best Score = 0.4091, Best Params = {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}
SVC: Best Score = 0.6818, Best Params = {'C': 5.0, 'kernel': 'linear'}

--- Evaluating Models using Best Parameters found during Tuning ---
--- Using LeaveOneOut Cross-Validation (22 splits) ---

Evaluating model: LogisticRegression with tuned parameters...
  No tuned parameters found or applied. Using default parameters.
  CV for LogisticRegression took 0.13 seconds.
--- Results for LogisticRegression (Aggregated over CV folds with Tuned Params) ---
Accuracy: 0.4545
F1 Score (Weighted): 0.4492
Classification Report:
               precision    recall  f1-score   support

         1.6       0.20      0.20      0.20         5
         1.8       0.00      0.00      0.00         5
         2.1       0.50      0.67      0.57         6
         2.4       1.00      0.83      0.91         6

    accuracy                           0.45        22
   macro avg       0.42      0.43      0.42        22
weighted avg       0.45      0.45      0.45        22

Confusion Matrix:
 [[1 3 1 0]
 [3 0 2 0]
 [1 1 4 0]
 [0 0 1 5]]

Evaluating model: RandomForest with tuned parameters...
  Applying Tuned Parameters: {'max_depth': 3, 'min_samples_split': 2, 'n_estimators': 50}
  CV for RandomForest took 0.57 seconds.
--- Results for RandomForest (Aggregated over CV folds with Tuned Params) ---
Accuracy: 0.3636
F1 Score (Weighted): 0.3636
Classification Report:
               precision    recall  f1-score   support

         1.6       0.00      0.00      0.00         5
         1.8       0.00      0.00      0.00         5
         2.1       0.33      0.33      0.33         6
         2.4       1.00      1.00      1.00         6

    accuracy                           0.36        22
   macro avg       0.33      0.33      0.33        22
weighted avg       0.36      0.36      0.36        22

Confusion Matrix:
 [[0 3 2 0]
 [3 0 2 0]
 [1 3 2 0]
 [0 0 0 6]]

Evaluating model: GradientBoosting with tuned parameters...
  Applying Tuned Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}
  CV for GradientBoosting took 1.40 seconds.
--- Results for GradientBoosting (Aggregated over CV folds with Tuned Params) ---
Accuracy: 0.4091
F1 Score (Weighted): 0.3815
Classification Report:
               precision    recall  f1-score   support

         1.6       0.33      0.20      0.25         5
         1.8       0.20      0.20      0.20         5
         2.1       0.17      0.17      0.17         6
         2.4       0.75      1.00      0.86         6

    accuracy                           0.41        22
   macro avg       0.36      0.39      0.37        22
weighted avg       0.37      0.41      0.38        22

Confusion Matrix:
 [[1 1 2 1]
 [1 1 3 0]
 [1 3 1 1]
 [0 0 0 6]]

Evaluating model: SVC with tuned parameters...
  Applying Tuned Parameters: {'C': 5.0, 'kernel': 'linear'}
  CV for SVC took 0.07 seconds.
--- Results for SVC (Aggregated over CV folds with Tuned Params) ---
Accuracy: 0.6818
F1 Score (Weighted): 0.6801
Classification Report:
               precision    recall  f1-score   support

         1.6       0.60      0.60      0.60         5
         1.8       0.50      0.40      0.44         5
         2.1       0.62      0.83      0.71         6
         2.4       1.00      0.83      0.91         6

    accuracy                           0.68        22
   macro avg       0.68      0.67      0.67        22
weighted avg       0.69      0.68      0.68        22

Confusion Matrix:
 [[3 1 1 0]
 [2 2 1 0]
 [0 1 5 0]
 [0 0 1 5]]

--- Best Individual Model based on CV f1_weighted (using tuned parameters): SVC ---
  f1_weighted: 0.6801
2025-04-07 20:40:24.920 python3[45447:12438743] +[IMKClient subclass]: chose IMKClient_Modern
2025-04-07 20:40:24.920 python3[45447:12438743] +[IMKInputSession subclass]: chose IMKInputSession_Modern
2025-04-07 20:40:28.079 python3[45447:12438743] The class 'NSSavePanel' overrides the method identifier.  This method is implemented by class 'NSWindow'

--- Skipping final model training and saving for now ---

--- Experiment Finished ---