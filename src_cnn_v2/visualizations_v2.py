# src_cnn_v2/visualizations_v2.py
"""
Contains functions to generate plots and visualizations for the V2 pipeline.
Loads data from the files generated by train_v2.py.
"""
import os
import sys
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Add project root to path for imports
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from src_cnn_v2 import config_v2 as cfg

# --- Plotting Configuration ---
sns.set_theme(style="whitegrid")
plt.rcParams["figure.figsize"] = (10, 6)

def plot_loss_curves(log_df, save_dir):
    """Plots and saves the training loss and validation MAE/RMSE curves."""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))

    # Plot Training Loss
    ax1.plot(log_df['epoch'], log_df['train_loss'], label='Training Loss (log-space MSE)', color='blue')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training Loss Curve')
    ax1.legend()
    ax1.grid(True)

    # Plot Validation Metrics
    ax2.plot(log_df['epoch'], log_df['val_mae'], label='Validation MAE', color='green')
    ax2.plot(log_df['epoch'], log_df['val_rmse'], label='Validation RMSE', color='orange')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Error (L/min)')
    ax2.set_title('Validation Metrics Over Epochs')
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    save_path = os.path.join(save_dir, "loss_and_metrics_curves.png")
    plt.savefig(save_path)
    print(f"Saved loss and metrics curves to: {save_path}")
    plt.close()

def plot_predictions_vs_true(preds_df, save_dir, title="Test Set"):
    """Plots a scatter plot of predicted vs. true values."""
    true_vals = preds_df['true_airflow']
    pred_vals = preds_df['predicted_airflow']
    
    mae = np.mean(np.abs(true_vals - pred_vals))
    rmse = np.sqrt(np.mean((true_vals - pred_vals)**2))
    ss_res = np.sum((true_vals - pred_vals)**2)
    ss_tot = np.sum((true_vals - np.mean(true_vals))**2)
    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0

    plt.figure(figsize=(8, 8))
    plt.scatter(true_vals, pred_vals, alpha=0.6, edgecolors='k')
    
    # Plot the "perfect prediction" line
    lims = [
        min(plt.xlim()[0], plt.ylim()[0]),
        max(plt.xlim()[1], plt.ylim()[1]),
    ]
    plt.plot(lims, lims, 'r--', lw=2, label='Perfect Prediction')
    
    plt.xlabel('True Airflow Rate (L/min)')
    plt.ylabel('Predicted Airflow Rate (L/min)')
    plt.title(f'{title}: True vs. Predicted\nRÂ² = {r2:.4f} | MAE = {mae:.4f} | RMSE = {rmse:.4f}')
    plt.legend()
    plt.grid(True)
    plt.axis('equal')
    plt.tight_layout()
    
    save_path = os.path.join(save_dir, f"{title.lower().replace(' ', '_')}_predictions_vs_true.png")
    plt.savefig(save_path)
    print(f"Saved prediction scatter plot to: {save_path}")
    plt.close()
    
def plot_error_distribution(preds_df, save_dir, title="Test Set"):
    """Plots a histogram and KDE of the prediction errors."""
    errors = preds_df['predicted_airflow'] - preds_df['true_airflow']
    
    plt.figure(figsize=(10, 6))
    sns.histplot(errors, kde=True, bins=20)
    plt.axvline(0, color='r', linestyle='--')
    plt.title(f'Distribution of Prediction Errors ({title})')
    plt.xlabel('Error (Predicted - True)')
    plt.ylabel('Frequency')
    
    save_path = os.path.join(save_dir, f"{title.lower().replace(' ', '_')}_error_distribution.png")
    plt.savefig(save_path)
    print(f"Saved error distribution plot to: {save_path}")
    plt.close()

def plot_diagnostic_distributions(df_orig, df_scaled, predictions, save_dir):
    """Plots distributions of key values for diagnosing prediction issues."""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))

    # Plot distribution of original and scaled delta_T
    sns.kdeplot(df_orig['delta_T'], ax=ax1, label='Original delta_T', color='blue', fill=True)
    sns.kdeplot(df_scaled['delta_T'], ax=ax1, label='Scaled delta_T', color='orange', fill=True)
    ax1.set_title('Distribution of delta_T (Original vs. Scaled)')
    ax1.legend()

    # Plot distribution of final predictions
    sns.histplot(predictions, ax=ax2, kde=True, bins=15)
    ax2.set_title('Distribution of Final Model Predictions (L/min)')
    ax2.set_xlabel('Predicted Airflow')

    plt.tight_layout()
    save_path = os.path.join(save_dir, "diagnostic_distributions.png")
    plt.savefig(save_path)
    print(f"Saved diagnostic distribution plots to: {save_path}")
    plt.close()
    
def main():
    print("--- Generating V2 Visualizations ---")
    
    # Define paths to the output files from training
    model_dir = os.path.join(cfg.OUTPUT_DIR, "trained_models")
    log_path = os.path.join(model_dir, "training_log.csv")
    test_preds_path = os.path.join(model_dir, "test_predictions.csv")
    
    # Create a directory for the plots
    plot_save_dir = os.path.join(cfg.OUTPUT_DIR, "visualizations")
    os.makedirs(plot_save_dir, exist_ok=True)
    
    # --- Generate Plots ---
    try:
        log_df = pd.read_csv(log_path)
        plot_loss_curves(log_df, plot_save_dir)
    except FileNotFoundError:
        print(f"Warning: Training log not found at '{log_path}'. Skipping loss curve plot.")
        
    try:
        test_preds_df = pd.read_csv(test_preds_path)
        plot_predictions_vs_true(test_preds_df, plot_save_dir, title="Test Set Performance")
        plot_error_distribution(test_preds_df, plot_save_dir, title="Test Set")
    except FileNotFoundError:
        print(f"Warning: Test predictions not found at '{test_preds_path}'. Skipping test set plots.")

    

    print("\n--- Visualization Complete ---")

if __name__ == "__main__":
    main()

# python src_cnn_v2/visualizations_v2.py